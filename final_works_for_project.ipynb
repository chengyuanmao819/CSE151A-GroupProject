{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lovek\\AppData\\Local\\Temp\\ipykernel_10280\\999191122.py:1: DtypeWarning: Columns (28,29,68) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = pd.read_csv('./data/US/combined_listings.csv')\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('./data/US/combined_listings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Exploration and Preprocessing\n",
    "Note: In practice, the process of data analysis often involves a combination of both data preprocessing and data exploration, and the order can be somewhat iterative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Initial Data Exploration\n",
    "Objective: Get a general sense of the data.\n",
    "\n",
    "Activities:\n",
    "1. Load the data.*\n",
    "2. Conduct preliminary descriptive statistics (mean, median, mode, etc.).*\n",
    "3. Generate basic visualizations (histograms, scatter plots, etc.).*\n",
    "4. Look for obvious issues such as missing values, duplicates, or outliers.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Data Proprocessing\n",
    "Objective: Clean and prepare the data for detailed analysis and modeling.\n",
    "\n",
    "Activities:\n",
    "1. Handle missing values (imputation, deletion).*\n",
    "2. Remove or correct inconsistencies and duplicates.* (????should we outliers ???)\n",
    "3. Normalize or standardize numerical data.*\n",
    "4. Encode categorical variables. (in our case, we don't need this unless we want to classify the interval of prices.)\n",
    "5. Scale features.???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Detailed Data Exploration\n",
    "Objective: Gain deeper insights into the cleaned and preprocessed data.\n",
    "\n",
    "Activities:\n",
    "1. Perform more detailed statistical analyses.*\n",
    "2. Create more sophisticated visualizations to uncover hidden patterns.*\n",
    "3. Conduct correlation analysis to identify relationships between variables.*\n",
    "4. Formulate and test initial hypotheses based on the cleaned data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Iterative Refinement (Optional)\n",
    "Objective: Refine your understanding and preparation of the data.\n",
    "\n",
    "Activities:\n",
    "1. Revisit data preprocessing steps as new insights are gained.\n",
    "2. Continue exploring the data in greater detail as needed.\n",
    "3. Adjust preprocessing techniques based on exploration findings (e.g., new outliers detected, better ways to handle missing values).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Initial Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: Choose the most appropriate initial model based on data exploration and preprocessing insights.\n",
    "\n",
    "We may use with keras sequential()\n",
    "\n",
    "Activities:\n",
    "1. Review the distribution of your target variable and main features.*\n",
    "2. Ensure that the chosen model aligns with the nature of the data (e.g., linear vs. non-linear, categorical vs. numerical).*\n",
    "3. Start with Simple Models simple baseline models like *\n",
    "      1. Linear Regression for regression tasks \n",
    "      2. or Logistic Regression for classification tasks.\n",
    "4. Ensure your data roughly meets the assumptions of the chosen simple model (e.g., linearity for Linear Regression).*\n",
    "5. Reason or Discuss why choose this Initial Model *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Design Initial Neural Network (if applicable):\n",
    "Determine Network Architecture:\n",
    "1. Number of Layers: Start with a simple architecture, such as one or two hidden layers.\n",
    "2. Number of Nodes per Layer: Begin with a small number of nodes, such as 10-50 per hidden layer, depending on the complexity of your data.\n",
    "3. Activation Functions: Choose activation functions based on the nature of the data and the task:\n",
    "   1. ReLU (Rectified Linear Unit): Common for hidden layers due to its simplicity and effectiveness.\n",
    "   2. Sigmoid or Softmax: Use Sigmoid for binary classification outputs and Softmax for multi-class classification outputs.\n",
    "   3. Linear Activation: Often used in the output layer for regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics and Technique(AKA Method)\n",
    "\n",
    "1. Classification Models' Metrics\n",
    "   1. Accuracy: The proportion of correctly classified instances among the total instances.\n",
    "   2. Precision: The proportion of true positive instances among the instances predicted as positive.\n",
    "   3. Recall (Sensitivity or True Positive Rate): The proportion of true positive instances among the actual positive instances.\n",
    "   4. F1 Score: The harmonic mean of precision and recall, providing a single metric that balances both.\n",
    "   5. Confusion Matrix: A table showing the true positives, true negatives, false positives, and false negatives.\n",
    "   6. ROC Curve (Receiver Operating Characteristic Curve): A graphical representation of the true positive rate vs. the false positive rate at various threshold settings.\n",
    "   7. AUC (Area Under the ROC Curve): A single metric that summarizes the ROC curve, indicating the model's ability to discriminate between classes.\n",
    "   8. Log Loss (Cross-Entropy Loss): Measures the performance of a classification model where the output is a probability value between 0 and 1.\n",
    "   9. Precision-Recall Curve: A graphical representation of precision vs. recall at various threshold settings.\n",
    "   10. Specificity (True Negative Rate): The proportion of true negative instances among the actual negative instances.\n",
    "2. Regression Models' Metrics\n",
    "   1. Mean Absolute Error (MAE): The average of the absolute differences between the predicted and actual values.\n",
    "   2. Mean Squared Error (MSE): The average of the squared differences between the predicted and actual values.\n",
    "   3. Root Mean Squared Error (RMSE): The square root of the average of the squared differences between the predicted and actual values.\n",
    "   4. R-Squared (Coefficient of Determination): Indicates the proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
    "   5. Adjusted R-Squared: Adjusted version of R-Squared that accounts for the number of predictors in the model.\n",
    "   6. Mean Absolute Percentage Error (MAPE): The average of the absolute percentage differences between the predicted and actual values.\n",
    "   7. Median Absolute Error: The median of the absolute differences between the predicted and actual values.\n",
    "3. Clustering Models' Metrics\n",
    "   1. Silhouette Score: Measures how similar an object is to its own cluster compared to other clusters.\n",
    "   2. Davies-Bouldin Index: Measures the average similarity ratio of each cluster with the one most similar to it.\n",
    "   3. Inertia (Within-Cluster Sum of Squares): Measures the compactness of the clusters, with lower values indicating better-defined clusters.\n",
    "   4. Calinski-Harabasz Index (Variance Ratio Criterion): Measures the ratio of the sum of between-cluster dispersion to within-cluster dispersion.\n",
    "4. Time Series Models' Metrics\n",
    "   1. Mean Absolute Error (MAE): The average of the absolute differences between the predicted and actual values.\n",
    "   2. Mean Squared Error (MSE): The average of the squared differences between the predicted and actual values.\n",
    "   3. Root Mean Squared Error (RMSE): The square root of the average of the squared differences between the predicted and actual values.\n",
    "   4. Mean Absolute Percentage Error (MAPE): The average of the absolute percentage differences between the predicted and actual values.\n",
    "   5. Mean Squared Logarithmic Error (MSLE): The average of the squared logarithmic differences between the predicted and actual values.\n",
    "5. Model Evaluation Techniques\n",
    "   1. Cross-Validation: A technique to assess how the results of a statistical analysis will generalize to an independent data set, commonly k-fold cross-validation.\n",
    "   2. Train-Test Split: Splitting the dataset into a training set and a test set to evaluate the model's performance.\n",
    "   3. Bootstrapping: A resampling technique used to estimate statistics on a population by sampling a dataset with replacement.\n",
    "   4. Learning Curve: A plot of model learning performance over time or over different training set sizes.\n",
    "   5. Validation Curve: A plot of training and validation scores with respect to the model hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Choose Some Evaluation Methods and Implements them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Reasons for Choosing Those Metrics and Techniques\n",
    "1. Why we choose these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Discussion\n",
    "1. What is the results of each metrics and techniques mean.\n",
    "2. What is the follow up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Hyperparameter Tuning\n",
    "Objective: Optimize the hyperparameters of your model to improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Identify Hyperparameters\n",
    "Objective: Focus on the key hyperparameters that significantly impact model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Choose a Tunning Method\n",
    "Objective: Ensure that the method chosen aligns with the resources available (e.g., time, computational power)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select an appropriate method for hyperparameter tuning. Common methods include:\n",
    "1. Grid Search: Exhaustively search through a specified subset of hyperparameters. (This is in our course material.)\n",
    "2. Random Search: Randomly sample from a specified subset of hyperparameters.\n",
    "3. Bayesian Optimization: Use probabilistic models to select the most promising hyperparameters based on past evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Run the Tuning Process\n",
    "\n",
    "Note: need to split train_data into (train_data  val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4.  Analyze Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6. Validate the Optimized Model with test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Save the Document the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
